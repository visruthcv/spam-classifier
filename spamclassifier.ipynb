{"cells":[{"source":["# Importing Libraries"],"cell_type":"markdown","metadata":{}},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import pandas as pd\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","import pickle"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"source":["# Importing Dataset"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["df = pd.read_csv('spam.csv',encoding='ISO-8859-1')\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     v1                                                 v2 Unnamed: 2  \\\n","0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1   ham                      Ok lar... Joking wif u oni...        NaN   \n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3   ham  U dun say so early hor... U c already then say...        NaN   \n","4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","\n","  Unnamed: 3 Unnamed: 4  \n","0        NaN        NaN  \n","1        NaN        NaN  \n","2        NaN        NaN  \n","3        NaN        NaN  \n","4        NaN        NaN  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}]},{"source":["# Dropping Unnecessary Columns"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis='columns',inplace=True)\n","df.columns = ['label', 'message']\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  label                                            message\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":3}]},{"source":["# Tokenization & Stemming"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["ps = PorterStemmer()"],"execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["corpus = []\n","for i in range(0, len(df)):\n","    review = re.sub('[^a-zA-Z]', ' ', df['message'][i])\n","    review = review.lower()\n","    review = nltk.word_tokenize(review)\n","    \n","    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n","    review = ' '.join(review)\n","    corpus.append(review)"],"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n"," 'ok lar joke wif u oni',\n"," 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli',\n"," 'u dun say earli hor u c alreadi say',\n"," 'nah think goe usf live around though']"]},"metadata":{},"execution_count":6}],"source":["corpus[0:5]"]},{"source":["# Implementing Bag Of Words"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["cv = CountVectorizer(max_features = 5000)\n","X = cv.fit_transform(corpus).toarray()"],"execution_count":8,"outputs":[]},{"source":["# Create Countvectorizer Pickle File"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["pickle.dump(cv,open('transformer.pkl','wb'))"]},{"metadata":{"trusted":true},"cell_type":"code","source":["y = pd.get_dummies(df['label'])\n","y = y.iloc[:,1].values"],"execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# print(df['label'],\"\\n y = \",y)\n","# Ham = 0, Spam = 1"],"execution_count":11,"outputs":[]},{"source":["# Train Test Split"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)"],"execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Naive Bayes Model"]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB"],"execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["spam_detect_model = MultinomialNB()\n","spam_detect_model.fit(X_train,y_train)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB()"]},"metadata":{},"execution_count":14}]},{"metadata":{"trusted":true},"cell_type":"code","source":["y_pred = spam_detect_model.predict(X_test)"],"execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Accuracy & Result"]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,accuracy_score\n","cm = confusion_matrix(y_test,y_pred)\n","cm"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[935,  14],\n","       [  7, 159]], dtype=int64)"]},"metadata":{},"execution_count":16}]},{"metadata":{"trusted":true},"cell_type":"code","source":["acc_score = accuracy_score(y_test,y_pred)\n","acc_score"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9811659192825112"]},"metadata":{},"execution_count":17}]},{"source":["# Creating Pickle File of the Trained Model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["pickle.dump(spam_detect_model,open('model.pkl','wb'))"]}],"metadata":{"kernelspec":{"name":"python377jvsc74a57bd0c8786e068652b7f12a3e1bf2aa2bbfcb04eb64ab636cba77baf09f1ee5420691","display_name":"Python 3.7.7 64-bit (conda)"},"language_info":{"name":"python","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}